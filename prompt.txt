Bu projede şunu yapmak istiyorum

localde kullandığım bir Ollama var ve orada bir model çalıştırıyorum
bu modeli VSCode gibi IDE'lerde kullanmak istiyorum, public GPT'lere alternatif içeride datanın kalacağı bir işlem yapmak istiyorum
Anladığım kadarıyla Ollama'nın API'si var, oraya istek atarak modeli kullanabilirim
CoPilot'a Model olarak eklemeyi planlıyorum bunun için nasıl bir yol izlemeliyim?



Api isteklerim için OLLAMA_EXTRA_HEADERS={"X-Request-Source":"post_text_script"} bunu header'a eklemem lazım
ayrıca OLLAMA_API_KEY environment variable'ını da ayarlamam lazım



Bir sonraki adım olarak isterseniz bu logu hem console.log hem de Copilot Chat arayüzüne (stream.markdown) yazdırabilirim — hangisini istersiniz?


Ollama'dan dönen değer "chunk" içinde var bunu işleyip olduğu gibi dönmeini istiyorum.
bana lazım olan şey response'un tamamı değil, chunk'lar halinde gelmesi. ve bu chunk içinde json var.
bunu parse edip içinden content kısmını alıp ekrana yazdırmam lazım.
Örnek bir response'uda altta iletiyorum.
```json
{
  "id": "chatcmpl-b0698db8ae6329e5",
  "object": "chat.completion",
  "created": 1764839288,
  "model": "gaunernst/gemma-3-27b-it-int4-awq",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Merhaba! Size nasıl yardımcı olabilirim?",
        "refusal": null,
        "annotations": null,
        "audio": null,
        "function_call": null,
        "tool_calls": [],
        "reasoning": null,
        "reasoning_content": null
      },
      "logprobs": null,
      "finish_reason": "stop",
      "stop_reason": 106,
      "token_ids": null
    }
  ],
  "service_tier": null,
  "system_fingerprint": null,
  "usage": {
    "prompt_tokens": 68,
    "total_tokens": 77,
    "completion_tokens": 9,
    "prompt_tokens_details": null
  },
  "prompt_logprobs": null,
  "prompt_token_ids": null,
  "kv_transfer_params": null
}




bu extension'ı ayrı bir sidebar olarak açmak istiyorum, orada input alanı olacak ve kullanıcı oraya prompt'u yazacak
gönder butonuna bastığında bu prompt'u ollama'ya gönderecek ve cevapları orada gösterecek
bunu nasıl yapabilirim?
benzer extensionlar
- Copilot Chat
- Codex var benim bildiğim orası gibi olsun



undefined_publisher.lucid-vsx bunu nasıl düzeltirim?


log
2025-12-05 12:05:33.438 [info] ExtensionService#_doActivateExtension undefined_publisher.lucid-vsx, startup: false, activationEvent: 'onView:lucid.chatView'
2025-12-05 12:05:33.442 [info] Extension 'undefined_publisher.lucid-vsx' uses a document selector without scheme. Learn more about this: https://go.microsoft.com/fwlink/?linkid=872305
2025-12-05 12:07:00.344 [info] ExtensionService#_doActivateExtension undefined_publisher.lucid-vsx, startup: false, activationEvent: 'onView:lucid.chatView'
2025-12-05 12:12:04.846 [info] Extension 'undefined_publisher.lucid-vsx' uses a document selector without scheme. Learn more about this: https://go.microsoft.com/fwlink/?linkid=872305


- WebView'in tasarımı VSCode'un içinde kullanılan/tanımlı olan görünümle aynı olmalı
- WebView'de kullanıcıdan alınan prompt'u Ollama API'sine göndermek için gerekli JavaScript kodu eklenmeli
- API'den gelen yanıtları WebView içinde göstermek için gerekli kod eklenmeli
- WebView'in VSCode ile düzgün iletişim kurabilmesi için gerekli mesajlaşma mekanizması kurulmalı
- WebView'in açılması ve kapatılması için gerekli VSCode komutları eklenmeli
- WebView'in performansını optimize etmek için gerekli önlemler alınmalı
- WebView'in güvenliğini sağlamak için gerekli önlemler alınmalı


Genel görünümü copilot/codex ile benzer yapmalıyım
- WebView'in tasarımı VSCode'un içinde kullanılan/tanımlı olan görünümle aynı olmalı
- Text içinde alt satırlara geçiş yapılabilmeli
- Gönder butonu olmalı
- Gönderilen prompt ve alınan cevaplar arasında görsel bir ayrım olmalı
- Gönder butonu cevap gelene kadar pasif olmalı ve talep tamamlandığında tekrar aktif olmalı
- Clear butonu olmamalı
